{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352629ed-db26-4cb3-a153-4ebbe4ca2f09",
   "metadata": {},
   "source": [
    "# Exercise 07 CNN & Transfer Learning - Assignment\n",
    "\n",
    "<span style=\"color:red\">**The submission deadline of this assignment is 15/04/2024 23:59.**</span>\n",
    "\n",
    "<span style=\"color:red\">**Do not submit the saved `.pth` file of the trained CNN, because the file size is too big.**</span>\n",
    "\n",
    "## Pedagogy\n",
    "\n",
    "This notebook contains both theoretical explanations and executable cells to execute your code.\n",
    "\n",
    "When you see the <span style=\"color:red\">**[TBC]**</span> (To Be Completed) sign, it means that you need to perform an action else besides executing the cells of code that already exist. These actions can be:\n",
    "- Complete the code with proper comments\n",
    "- Respond to a question\n",
    "- Write an analysis\n",
    "- etc.\n",
    "\n",
    "## Requirement\n",
    "\n",
    "In this assignment, you are required to build a multi-class image classifier with pre-trained Squeeze Net using transfer learning.\n",
    "\n",
    "The problem to be solved is to classify grayscale images into one of the 10 pre-defined classes:\n",
    "\n",
    "![](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "|Label|0|1|2|3|4|5|6|7|8|9|\n",
    "|-|-|-|-|-|-|-|-|-|-|-|\n",
    "|Class|T-shit/top|Trouser|Pullover|Dress|Coat|Sandal|Shirt|Sneaker|Bag|Ankle boot|\n",
    "\n",
    "<span style=\"color:red\">**[TBC]**</span> Please complete the following tasks:\n",
    "- Build the data pipeline\n",
    "- Load pre-trained model and re-build the classifier\n",
    "- Train the re-built classifier\n",
    "- Test and evaluation\n",
    "- (Optional) Fine-tuning entire CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625b810-2f04-4e3b-be95-1568b2670036",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276980c-4420-4c4c-a506-172e3dfe1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TBC] complete your code here with proper comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107590dd-f069-4880-8c42-733a17742dba",
   "metadata": {},
   "source": [
    "## Task 1. Build the data pipeline\n",
    "\n",
    "You are required to use the PyTorch built-in Fashion MNIST dataset, consists of 70,000 $28\\times28$ grayscale images in 10 classes, with 7,000 images per class. You can find more information about this dataset from the [PyTorch documentation](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html) and the [original source](https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "To use the Fashion MNIST dataset and the pre-trained Squeeze Net, apart from the pre-processing transformations illustrated in the Instruction notebook, you also need to convert the grayscale image to the RGB image. To do this, you can add an additional transformation `transforms.Grayscale(num_output_channels=3)` to the sequence of transformations you defined.\n",
    "\n",
    "<span style=\"color:red\">**[TBC]**</span> You need to:\n",
    "- Define a sequence of transformations to pre-process the images\n",
    "- Use `torchvision.datasets.FashionMNIST()` to load the dataset\n",
    "- Divide the dataset into the training, valiation, and test set\n",
    "- Create `DataLoader` instance to wrap the dataset as iterable objects\n",
    "    - Decide a proper batch size considering\n",
    "        - The available memory of your computer\n",
    "        - The desired number of batches in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0454d87-ed90-4268-9ec8-8f8a8cfe9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TBC] complete your code here with proper comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a04f4-00db-465e-9630-9079c05a7a4f",
   "metadata": {},
   "source": [
    "## Task 2. Load Pre-trained model and Re-build the classifier \n",
    "\n",
    "<span style=\"color:red\">**[TBC]**</span> You need to:\n",
    "- Load the pre-trained Squeeze Net\n",
    "- Replace the `classifier` part\n",
    "- Freeze the `features` part\n",
    "- Set up GPU acceleration if it's possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963b3ef-974b-4978-bedc-c0c378b9e00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [TBC] complete your code here with proper comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511e9db-363b-4294-8e77-08923752652b",
   "metadata": {},
   "source": [
    "## Task 3. Train the re-built classifier\n",
    "\n",
    "<span style=\"color:red\">**[TBC]**</span> You need to:\n",
    "\n",
    "- Define a `train()` function\n",
    "    - Embed automatic model saving in the training process\n",
    "    - <span style=\"color:red\">**Do not submit the saved file as it will be too big.**</span>\n",
    "- Specify the training hyper-parameters\n",
    "- Train the network\n",
    "- Reload the best model after training\n",
    "- Plot the loss history of the training probess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb326330-4a75-499f-9add-e4087aa86ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TBC] complete your code here with proper comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec588df3-9dd5-44db-9ea3-8609cddcd234",
   "metadata": {},
   "source": [
    "## Step 4. Test and evaluation\n",
    "\n",
    "<span style=\"color:red\">**[TBC]**</span> You need to:\n",
    "- Define the `test()` function\n",
    "    - Output logits, probabilities and predictions\n",
    "    - Output the loss value on the test set\n",
    "- Make predictions on the test dataset\n",
    "- Evaluate the performance\n",
    "    - Use `sklearn.metrics.classification_report()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c14b8-647e-4992-9eb8-070cd38933b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TBC] complete your code here with proper comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aed7ba-fc9e-421b-b5a9-1fece5677f99",
   "metadata": {},
   "source": [
    "## Optional Task. Fine-tuning entire CNN\n",
    "\n",
    "This task is not mandatory. You need to:\n",
    "- Unfreeze the `feature extractor`\n",
    "- Fine-tune the entire netowrk (both the `feature extractor` and the `classifier`) with a relative small learning rate\n",
    "- Reload the best model after fine-tuning\n",
    "- Test and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80ba03-203c-4d4e-9519-9b5366fb6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TBC] complete your code here with proper comments\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
